{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944c5709-1a93-4792-8de4-ae7111b11f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import shutil\n",
    "import argparse\n",
    "from glob import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sber_path = \"data/sber\"\n",
    "os.makedirs(f\"{sber_path}/json\", exist_ok=True)\n",
    "os.makedirs(f\"{sber_path}/train_jsons\", exist_ok=True)\n",
    "os.makedirs(f\"{sber_path}/test_jsons\", exist_ok=True)\n",
    "\n",
    "with open(f\"{sber_path}/result_with_text.json\", 'r') as f:\n",
    "    sber = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef75784-99b2-45d9-9fc1-c42150251844",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sber['images']\n",
    "categories = sber['categories']\n",
    "annotations = sber['annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc5b7632-a3d1-427e-b19f-68e6af203026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and save annotations in NER format\n",
    "for img in images:\n",
    "    img_id = img['id']\n",
    "    img_file = img['file_name']\n",
    "    W, H = img['width'], img['height']\n",
    "    # Group annotations by image\n",
    "    img_annots = []\n",
    "    for ann in annotations:\n",
    "        if ann['image_id'] == img_id:\n",
    "            img_annots.append(ann)\n",
    "\n",
    "    # Filter objects with less than 2 elements\n",
    "    # if len(img_annots) <= 1:\n",
    "    #     continue\n",
    "\n",
    "    form = []\n",
    "    for ann in img_annots:\n",
    "        text = ann['text']\n",
    "        category_id = ann['category_id']\n",
    "        category = categories[ann['category_id']]['name']\n",
    "        x1, y1, w, h = ann['bbox']\n",
    "        \n",
    "        # Filter invalid bounding boxes\n",
    "        if x1 + w > W or y1 + h > H:\n",
    "            continue\n",
    "\n",
    "        box = [x1, y1, w, h]\n",
    "        \n",
    "        cord_like_ann = {\n",
    "            \"label\": category,\n",
    "            \"label_id\": category_id,\n",
    "            \"words\": [{\"box\": box, \"text\": text}],\n",
    "        }\n",
    "\n",
    "        form.append(cord_like_ann)\n",
    "\n",
    "    img_json = {\n",
    "        \"form\": form,\n",
    "        \"meta\": {\n",
    "            \"split\": \"UNK\",\n",
    "            \"image_id\": img_id,\n",
    "            \"image\": img_file,\n",
    "            \"image_size\": {\n",
    "                \"width\": img['width'],\n",
    "                \"height\": img['height']\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Saving\n",
    "    file = os.path.split(img_file)[-1].replace('.png', '.json')\n",
    "    with open(f\"{sber_path}/json/{file}\", 'w') as f:\n",
    "        json.dump(img_json, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f88a6e33-66b1-486a-a000-6f37f625e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 640\n",
      "train/test: 512/128\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "files = glob(f\"{sber_path}/json/*\")\n",
    "print(\"Dataset size:\", len(files))\n",
    "\n",
    "files_train, files_test = train_test_split(files, test_size=0.2, random_state=42)\n",
    "sets_dict = {\"train\": files_train, \"test\": files_test}\n",
    "print(f\"train/test: {len(files_train)}/{len(files_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94554435-020d-4db0-aed7-7b25b1b75e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set in sets_dict:\n",
    "    base_files = sets_dict[set]\n",
    "    for file in base_files:\n",
    "        new_file = file.replace('/json', f'/{set}_jsons')\n",
    "        os.rename(file, new_file)\n",
    "\n",
    "for set in ['train', 'test']:\n",
    "    for file in glob(f\"{sber_path}/{set}/json/*.json\"):\n",
    "        data = json.load(f, 'r')\n",
    "        data['meta']['split'] = set\n",
    "        json.dump(data, open(file, 'w'))\n",
    "\n",
    "shutil.rmtree(f\"{sber_path}/json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7fe3714-1cde-40f8-9331-87628193ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save images and categories data\n",
    "meta = {\"images\": images, \"categories\": categories}\n",
    "with open(f\"{sber_path}/meta.json\", 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ccc4c3-c3e7-4ce4-aa52-6e6a26f2557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 640\n",
      "train/test: 512/128\n"
     ]
    }
   ],
   "source": [
    "!python utils/sber2ner.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
